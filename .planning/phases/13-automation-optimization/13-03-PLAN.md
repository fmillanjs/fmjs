---
phase: 13-automation-optimization
plan: 03
type: execute
wave: 2
depends_on:
  - 13-01
  - 13-02
files_modified:
  - apps/web/lighthouserc.json
  - .github/workflows/deploy.yml
autonomous: false
requirements:
  - MIG-04

must_haves:
  truths:
    - "Lighthouse CI checks public portfolio routes for performance ≥90 and fails the build on performance regressions"
    - "Lighthouse job runs in CI after the test job passes"
    - "Human has verified the complete automation layer (visual regression, ESLint governance, Lighthouse) is functional"
  artifacts:
    - path: "apps/web/lighthouserc.json"
      provides: "Lighthouse CI config asserting performance ≥0.9 on public portfolio routes"
      contains: "categories:performance"
    - path: ".github/workflows/deploy.yml"
      provides: "Lighthouse CI job after test job, with @lhci/cli installed globally"
      contains: "lhci autorun"
  key_links:
    - from: ".github/workflows/deploy.yml"
      to: "apps/web/lighthouserc.json"
      via: "lhci autorun reads lighthouserc.json from apps/web/"
      pattern: "lhci autorun"
    - from: "apps/web/lighthouserc.json"
      to: "http://localhost:3000/"
      via: "lhci collect startServerCommand"
      pattern: "startServerCommand"
---

<objective>
Add Lighthouse CI for automated performance gating on public portfolio routes, then verify the complete Phase 13 automation layer works end-to-end.

Purpose: Phase success criterion #1 requires CI to fail on WCAG violations (already done in plan 01), #5 requires Lighthouse ≥90 for critical routes. This plan adds `lighthouserc.json` scoped to public (unauthenticated) routes and a `lighthouse` job in GitHub Actions that runs after `test` passes. The human verification checkpoint confirms the full automation layer is working as designed.
Output: `apps/web/lighthouserc.json` + Lighthouse job in `deploy.yml` + human approval of Phase 13 automation.
</objective>

<execution_context>
@/home/doctor/.claude/get-shit-done/workflows/execute-plan.md
@/home/doctor/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-automation-optimization/13-RESEARCH.md
@.planning/phases/13-automation-optimization/13-01-SUMMARY.md
@.planning/phases/13-automation-optimization/13-02-SUMMARY.md
@.github/workflows/deploy.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create lighthouserc.json and add Lighthouse CI job to deploy.yml</name>
  <files>
    apps/web/lighthouserc.json
    .github/workflows/deploy.yml
  </files>
  <action>
**Step 1: Create `apps/web/lighthouserc.json`**

Create this file with the exact configuration from the research doc. Key decisions:
- Scope to public portfolio routes ONLY (dashboard routes cannot be audited by lhci — it cannot authenticate)
- Include `/login` since it is public and performance-relevant
- `numberOfRuns: 3` for median reliability
- `categories:performance: ["error", { "minScore": 0.9 }]` — FAIL CI on performance < 90
- `categories:accessibility: ["warn", { "minScore": 1 }]` — WARN only (axe is authoritative; avoid duplicate failures)
- `upload.target: "temporary-public-storage"` — no GitHub App token required; reports stored on Google GCS temporarily

```json
{
  "ci": {
    "collect": {
      "startServerCommand": "npm run start",
      "startServerReadyPattern": "ready",
      "startServerReadyTimeout": 30000,
      "url": [
        "http://localhost:3000/",
        "http://localhost:3000/about",
        "http://localhost:3000/projects",
        "http://localhost:3000/projects/teamflow",
        "http://localhost:3000/login"
      ],
      "numberOfRuns": 3
    },
    "assert": {
      "assertions": {
        "categories:performance": ["error", { "minScore": 0.9 }],
        "categories:accessibility": ["warn", { "minScore": 1 }]
      }
    },
    "upload": {
      "target": "temporary-public-storage"
    }
  }
}
```

**Step 2: Add Lighthouse CI job to `.github/workflows/deploy.yml`**

Read the current deploy.yml (it has `test`, `build-and-push`, and `deploy` jobs after plan 01 updates).

Add a new `lighthouse` job AFTER the test job and BEFORE build-and-push. It `needs: test` (runs after tests pass, in parallel with build-and-push):

```yaml
  lighthouse:
    name: Lighthouse CI
    runs-on: ubuntu-latest
    needs: test
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Generate Prisma Client
        run: npx prisma generate --schema=packages/database/prisma/schema.prisma

      - name: Build Next.js app
        run: cd apps/web && npm run build
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5434/teamflow
          NEXTAUTH_SECRET: test-secret-min-32-chars-required-for-jwt
          NEXTAUTH_URL: http://localhost:3000
          NEXT_PUBLIC_API_URL: http://localhost:3001

      - name: Install Lighthouse CI
        run: npm install -g @lhci/cli@0.15.x

      - name: Run Lighthouse CI
        run: cd apps/web && lhci autorun
        env:
          NEXTAUTH_SECRET: test-secret-min-32-chars-required-for-jwt
          NEXTAUTH_URL: http://localhost:3000
          NEXT_PUBLIC_API_URL: http://localhost:3001

      - name: Upload Lighthouse reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-reports
          path: apps/web/.lighthouseci/
          retention-days: 7
```

IMPORTANT: The `build-and-push` job must also `needs: [test, lighthouse]` so Docker images are only pushed after Lighthouse passes. Update `build-and-push.needs` from `test` to `[test, lighthouse]`.

After editing, validate YAML:
```bash
python3 -c "import yaml; yaml.safe_load(open('.github/workflows/deploy.yml'))" && echo "YAML valid"
```
  </action>
  <verify>
1. Lighthouse config exists: `ls apps/web/lighthouserc.json`
2. Config is valid JSON: `python3 -m json.tool apps/web/lighthouserc.json && echo "JSON valid"`
3. Config scopes to public routes only: `grep -c "localhost:3000/teams" apps/web/lighthouserc.json` — expect 0 (no dashboard routes)
4. CI has lighthouse job: `grep -c "lighthouse:" .github/workflows/deploy.yml` — expect 1
5. CI has lhci autorun: `grep "lhci autorun" .github/workflows/deploy.yml`
6. build-and-push depends on lighthouse: `grep -A3 "build-and-push:" .github/workflows/deploy.yml | grep "lighthouse"`
7. YAML valid: `python3 -c "import yaml; yaml.safe_load(open('.github/workflows/deploy.yml'))" && echo valid`
  </verify>
  <done>
`apps/web/lighthouserc.json` exists with performance ≥0.9 assertion on 5 public routes. `deploy.yml` has `lighthouse` job after `test`, `build-and-push` waits for both `test` and `lighthouse`. YAML is valid.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Human verification of Phase 13 automation layer</name>
  <what-built>
Complete Phase 13 automation layer:
- Plan 01: Dashboard visual regression spec (8 tests, 6-8 PNG baselines), CI split into named accessibility + visual regression + remaining E2E steps, ESLint governance check added to CI
- Plan 02: 3 deprecated component usages replaced in components/tasks/, ESLint exemptions removed for all migrated directories, @next/bundle-analyzer installed and integrated, bundle baseline measured
- Plan 03 (just now): lighthouserc.json asserting Lighthouse performance ≥90 on 5 public routes, Lighthouse CI job added to deploy.yml after test job
  </what-built>
  <how-to-verify>
1. **Visual regression tests work locally:**
   ```bash
   cd apps/web && npx playwright test e2e/dashboard/visual-regression.spec.ts
   ```
   Expected: All tests pass (or skip for project-board if no seed data). No failures.

2. **ESLint governance is enforced:**
   ```bash
   cd apps/web && npx next lint
   ```
   Expected: exits 0 with no errors. (Previously exempted directories are now enforced.)

3. **Test for governance enforcement** — create a temp file that imports a deprecated component and verify ESLint catches it:
   ```bash
   echo "import { EmptyState } from '@/components/ui/empty-state'" > /tmp/test-governance.tsx
   cp /tmp/test-governance.tsx apps/web/components/tasks/test-governance.tsx
   cd apps/web && npx next lint components/tasks/test-governance.tsx 2>&1 | grep "DESIGN SYSTEM"
   rm apps/web/components/tasks/test-governance.tsx
   ```
   Expected: Should output the DESIGN SYSTEM error message. (This confirms governance works.)

4. **Bundle analyzer works:**
   ```bash
   cd apps/web && ANALYZE=true npm run build 2>&1 | tail -5
   ```
   Expected: Build succeeds (exit 0). HTML reports generated in `.next/analyze/`.

5. **Lighthouse config is valid:**
   ```bash
   python3 -m json.tool apps/web/lighthouserc.json
   ```
   Expected: Valid JSON output with performance assertion.

6. **CI workflow is valid YAML:**
   ```bash
   python3 -c "import yaml; yaml.safe_load(open('.github/workflows/deploy.yml'))" && echo "VALID"
   ```
   Expected: VALID printed.

7. **Review the CI changes feel right:** Open `.github/workflows/deploy.yml` and confirm the Lighthouse job is present and structured correctly.
  </how-to-verify>
  <action>Run the verification steps listed in how-to-verify above. If all checks pass, type "approved".</action>
  <verify>All 7 verification steps in how-to-verify pass without errors.</verify>
  <done>Human approves that the complete Phase 13 automation layer is working: visual regression tests pass, ESLint governance enforces, bundle analyzer works, Lighthouse config is valid, CI YAML is valid.</done>
  <resume-signal>Type "approved" to complete Phase 13, or describe any issues found</resume-signal>
</task>

</tasks>

<verification>
1. `python3 -m json.tool apps/web/lighthouserc.json` — valid JSON
2. `grep "lhci autorun" .github/workflows/deploy.yml` — present
3. `grep -c "localhost:3000/teams" apps/web/lighthouserc.json` — 0 (no auth routes)
4. `cd apps/web && npx playwright test e2e/dashboard/visual-regression.spec.ts` — 0 failures
5. `cd apps/web && npx next lint` — 0 errors
6. `python3 -c "import yaml; yaml.safe_load(open('.github/workflows/deploy.yml'))" && echo VALID` — VALID
</verification>

<success_criteria>
All 5 Phase 13 success criteria met:
1. CI/CD pipeline fails on WCAG violations — axe-core accessibility tests in named CI step
2. Visual regression tests detect dark mode issues — dashboard visual-regression.spec.ts with 8 tests in both themes
3. Bundle size measured and documented (decreased or documented with justification)
4. Playwright visual regression suite captures all major routes in both themes (portfolio 12 + dashboard 6-8)
5. Lighthouse performance ≥90 enforced for critical public routes via lhci autorun
</success_criteria>

<output>
After completion, create `.planning/phases/13-automation-optimization/13-03-SUMMARY.md`
</output>
