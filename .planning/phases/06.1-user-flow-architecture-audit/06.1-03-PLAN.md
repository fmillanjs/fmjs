---
phase: 06.1-user-flow-architecture-audit
plan: 03
type: execute
wave: 2
depends_on: [06.1-01, 06.1-02]
files_modified:
  - .planning/phases/06.1-user-flow-architecture-audit/EDGE-CASE-CHECKLIST.md
  - apps/web/e2e/edge-cases/loading-states.spec.ts
  - apps/web/e2e/edge-cases/error-states.spec.ts
  - apps/web/e2e/edge-cases/empty-states.spec.ts
  - apps/web/e2e/edge-cases/permission-errors.spec.ts
autonomous: false

must_haves:
  truths:
    - "All edge cases handled: empty states, loading states, error states, invalid routes, missing permissions"
    - "Navigation structure is consistent: breadcrumbs, back buttons, sidebar state preserved"
  artifacts:
    - path: ".planning/phases/06.1-user-flow-architecture-audit/EDGE-CASE-CHECKLIST.md"
      provides: "Systematic checklist covering all edge case categories with test status tracking"
      min_lines: 100
    - path: "apps/web/e2e/edge-cases/loading-states.spec.ts"
      provides: "E2E tests validating loading skeletons, spinners, and loading indicators"
      min_lines: 60
    - path: "apps/web/e2e/edge-cases/error-states.spec.ts"
      provides: "E2E tests validating error messages, 404/500 pages, network failures, and retry flows"
      min_lines: 80
    - path: "apps/web/e2e/edge-cases/empty-states.spec.ts"
      provides: "E2E tests validating empty state CTAs and guidance"
      min_lines: 60
    - path: "apps/web/e2e/edge-cases/permission-errors.spec.ts"
      provides: "E2E tests validating RBAC permission denials and role-based UI hiding"
      min_lines: 80
  key_links:
    - from: "apps/web/e2e/edge-cases/*.spec.ts"
      to: "frontend components"
      via: "Playwright selectors"
      pattern: "getByText.*[Ee]rror|[Ll]oading|[Ee]mpty"
    - from: "EDGE-CASE-CHECKLIST.md"
      to: "E2E test coverage"
      via: "manual verification tracking"
      pattern: "\\[x\\]"
---

<objective>
Systematically audit and test all edge cases across the application including loading states, error states, empty states, permission denials, and navigation edge cases, ensuring comprehensive UX polish and resilient error handling.

Purpose: Identify and fix gaps in edge case handling that E2E happy-path tests don't catch. Ensure users receive clear guidance in all non-ideal scenarios (network failures, empty data, missing permissions, invalid routes).

Output: Comprehensive edge case checklist, automated E2E tests for critical edge cases, and manual verification checkpoint for visual/UX validation.
</objective>

<execution_context>
@/home/doctor/.claude/get-shit-done/workflows/execute-plan.md
@/home/doctor/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06.1-user-flow-architecture-audit/06.1-RESEARCH.md

# Existing empty state components
@apps/web/components/ui/empty-state.tsx

# Existing error boundaries
@apps/web/app/(dashboard)/teams/error.tsx
@apps/web/app/(dashboard)/teams/[teamId]/projects/error.tsx

# Existing 404/500 pages
@apps/web/app/not-found.tsx
@apps/web/app/error.tsx

# Existing loading states
@apps/web/app/(dashboard)/teams/loading.tsx
@apps/web/components/ui/skeleton.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create systematic edge case checklist</name>
  <files>.planning/phases/06.1-user-flow-architecture-audit/EDGE-CASE-CHECKLIST.md</files>
  <action>
Create comprehensive edge case checklist organized by category, tracking automated test coverage and manual verification status.

Categories and items (based on 06.1-RESEARCH.md Pattern 4):

**Loading States:**
- [ ] Initial page load shows skeleton/spinner (Teams, Projects, Tasks)
- [ ] Subsequent navigation shows loading indicators
- [ ] Form submission shows loading state on button
- [ ] Infinite scroll shows loading indicator at bottom (Activity feed, Audit log)
- [ ] Data refetch shows subtle loading indicator (not full-page spinner)

**Error States:**
- [ ] Network error shows actionable error message with retry button
- [ ] 404 page shows for invalid routes with navigation back to home
- [ ] 500 error shows generic error with support contact
- [ ] Form validation errors show next to fields
- [ ] API error messages are user-friendly (not raw stack traces)
- [ ] Error boundaries catch component errors without crashing app

**Empty States:**
- [ ] No teams: Shows "Create your first team" CTA
- [ ] No projects in team: Shows "Create your first project" CTA
- [ ] No tasks in project: Shows "Add your first task" CTA
- [ ] No search results: Shows "No results found" with clear filters button
- [ ] No comments on task: Shows "Be the first to comment" placeholder
- [ ] No audit log entries: Shows "No activity yet" message

**Navigation Edge Cases:**
- [ ] Browser back button works correctly (no broken state)
- [ ] Breadcrumbs show correct hierarchy at all levels
- [ ] Sidebar active state matches current page
- [ ] Deep links (direct URL access) work when logged in
- [ ] Invalid resource IDs show 404 not error page
- [ ] Deleted resource redirects to parent (e.g., deleted project → team page)

**Permission Edge Cases:**
- [ ] Member cannot access admin-only pages (redirect with error)
- [ ] Member cannot see delete buttons (UI hidden)
- [ ] Manager can archive but not delete projects
- [ ] Last admin cannot remove themselves
- [ ] Invite link shows error if already member
- [ ] Non-member cannot access organization resources

**Data Integrity Edge Cases:**
- [ ] Optimistic UI rollback on API failure (drag-drop, inline edit)
- [ ] Concurrent edits show conflict warning
- [ ] Form resubmission prevention (double-click submit)
- [ ] Stale data refresh on focus (window.addEventListener('focus'))
- [ ] Orphaned records handled (task without project shows error)

For each item, track:
- Status: [ ] Not tested, [~] Partially tested, [x] Verified
- Test type: Auto (E2E), Manual (visual check), N/A
- Notes: Any issues found or fixes needed

Format as markdown table for easy tracking:
```markdown
| Category | Item | Status | Test Type | Notes |
|----------|------|--------|-----------|-------|
| Loading | Initial page load skeleton | [ ] | Auto | |
```

Include summary section at bottom tracking:
- Total items: X
- Automated: X (E2E coverage)
- Manual verification needed: X
- Passing: X
- Failing: X
  </action>
  <verify>
Check checklist structure:
```bash
cat .planning/phases/06.1-user-flow-architecture-audit/EDGE-CASE-CHECKLIST.md | grep -E "^## |^- \[|^\|"
```

Should show organized categories with checkbox items and table structure.
  </verify>
  <done>
Comprehensive edge case checklist created covering 6 categories (loading, error, empty, navigation, permission, data integrity) with 30+ items. Checklist includes status tracking, test type classification, and notes field for issues.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create automated edge case E2E tests</name>
  <files>
apps/web/e2e/edge-cases/loading-states.spec.ts
apps/web/e2e/edge-cases/error-states.spec.ts
apps/web/e2e/edge-cases/empty-states.spec.ts
apps/web/e2e/edge-cases/permission-errors.spec.ts
  </files>
  <action>
Create four E2E test suites validating critical edge cases that can be automated with Playwright.

**File 1: loading-states.spec.ts**
Tests:
1. Teams list shows skeleton on initial load, then data
2. Project board shows skeleton, then Kanban columns
3. Task detail shows skeleton, then full task
4. Form submit button shows loading state (disabled + spinner) during submission
5. Activity feed infinite scroll shows loading indicator at bottom

Pattern: Use page.waitForSelector() to detect skeleton, then expect data to appear within timeout.

**File 2: error-states.spec.ts**
Tests:
1. Network error: Mock network failure with page.route(), verify error message + retry button
2. 404 page: Navigate to /teams/nonexistent-id, verify 404 page with "Back to teams" link
3. 500 error: Mock server error (status 500), verify generic error page
4. Form validation: Submit empty form, verify error messages next to fields
5. API error: Mock 400 response with error message, verify user-friendly display (not stack trace)
6. Error boundary: Trigger component error (if test component exists), verify error boundary catches

Pattern: Use page.route() for network interception. Use page.goto() for invalid routes. Check for error message text and retry/navigation buttons.

**File 3: empty-states.spec.ts**
Tests:
1. No teams: New user account, verify "Create your first team" CTA
2. No projects: Team with no projects, verify "Create your first project" CTA
3. No tasks: Project with no tasks, verify "Add your first task" CTA
4. No search results: Search for "xyz123nonexistent", verify "No results found"
5. No comments: Task with no comments, verify "Be the first to comment"

Pattern: Setup test data with empty states, navigate to pages, verify EmptyState component appears with correct text and CTA buttons.

**File 4: permission-errors.spec.ts**
Tests:
1. Member accessing admin-only audit log: Login as member, navigate to /teams/{id}/audit-log, verify permission denied
2. Member cannot see delete buttons: Login as member, verify delete buttons hidden in project settings
3. Manager can archive but not delete: Login as manager, verify archive button visible, delete button hidden
4. Last admin protection: Attempt to remove last admin, verify error message preventing removal
5. Non-member access: Logout, try accessing organization page, verify redirect to login

Pattern: Use multiple test users with different roles (admin, manager, member). Use getByRole to check for button presence/absence. Verify error messages and redirects.

Follow existing E2E test patterns from apps/web/e2e/portfolio/*.spec.ts and authenticated/*.spec.ts. Use semantic selectors. Each test should be independent and clean up after itself.

Reference 06.1-RESEARCH.md Example 3 for edge case testing patterns. Use page.route() for network mocking, page.goto() for invalid routes, and role-based login for permission tests.
  </action>
  <verify>
Run all edge case E2E tests:
```bash
cd apps/web
npx playwright test e2e/edge-cases/ --project=chromium
```

All four test suites should pass. Check for clear test names and failure messages.
  </verify>
  <done>
Four E2E test suites created validating loading states (5 tests), error states (6 tests), empty states (5 tests), and permission errors (5 tests). All automated edge case tests pass, providing regression protection for UX polish.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Comprehensive edge case audit with automated E2E tests and systematic checklist covering loading, error, empty, navigation, permission, and data integrity scenarios.
  </what-built>
  <how-to-verify>
1. Review EDGE-CASE-CHECKLIST.md and manually verify items marked for manual testing:
   ```bash
   cat .planning/phases/06.1-user-flow-architecture-audit/EDGE-CASE-CHECKLIST.md
   ```

2. Run complete edge case test suite:
   ```bash
   cd apps/web
   npx playwright test e2e/edge-cases/ --project=chromium
   npx playwright show-report
   ```
   Verify all tests pass. Review HTML report for test execution details.

3. Manual UX verification (items not covered by automation):
   - Open http://localhost:3000 in browser
   - Test browser back button: Navigate Team → Project → Task, click back button twice, verify return to Team page (no broken state)
   - Test breadcrumbs: Verify breadcrumbs show correct hierarchy at Team/Project/Task levels
   - Test sidebar state: Expand team, navigate to project, verify sidebar team still expanded
   - Test optimistic UI rollback: Disconnect network, drag task to new column, verify rollback when API fails
   - Test concurrent edits: Open task in two browser windows, edit in both, verify conflict warning
   - Test stale data refresh: Open task list, leave tab idle 5 minutes, focus window, verify data refreshes

4. Update EDGE-CASE-CHECKLIST.md:
   - Mark automated tests as [x] verified
   - Mark manual tests as [x] verified or [ ] failed with notes
   - Update summary counts at bottom

5. Review findings:
   - How many items passed automated tests? (should be ~21/30+)
   - How many items passed manual verification? (should be ~9/30+)
   - Are there any failing edge cases that need fixes?
   - Are loading/error/empty states consistent across all pages?
   - Are permission denials clear and actionable?

If any edge cases fail or have poor UX, note in checklist for future fixing plan.
  </how-to-verify>
  <resume-signal>
Reply with:
- "approved" if all critical edge cases pass and UX is polished
- Or describe specific issues found (e.g., "No loading skeleton on project page", "404 page missing back link", "Permission error shows stack trace")
  </resume-signal>
</task>

</tasks>

<verification>
Complete edge case audit verification:

1. Automated coverage:
```bash
cd apps/web
npx playwright test e2e/edge-cases/ --project=chromium
```
Should show 21+ tests passing across 4 edge case categories.

2. Manual verification:
Review EDGE-CASE-CHECKLIST.md and verify all manual test items are checked off with notes.

3. Coverage summary:
```bash
cat .planning/phases/06.1-user-flow-architecture-audit/EDGE-CASE-CHECKLIST.md | grep -E "^\[x\]" | wc -l
```
Should show 30+ items verified.

4. Combined verification:
All success criteria from Phase 6.1 related to edge cases, navigation consistency, and error handling should be TRUE after this plan completes.
</verification>

<success_criteria>
1. Systematic edge case checklist created covering 6 categories with 30+ items
2. Automated E2E tests validate 21+ edge cases (loading, error, empty, permission scenarios)
3. Manual verification completes remaining edge cases (browser behavior, optimistic UI, concurrent edits)
4. All critical edge cases either pass or are documented in checklist with notes for fixing
5. Loading states show skeletons/spinners appropriately across all major pages
6. Error states show user-friendly messages with retry/navigation options
7. Empty states show clear CTAs guiding users to next action
8. Permission errors show clear explanations of required role
9. Navigation edge cases (back button, breadcrumbs, sidebar state) work correctly
10. Data integrity edge cases (optimistic UI, concurrent edits, stale data) handle gracefully
</success_criteria>

<output>
After completion, create `.planning/phases/06.1-user-flow-architecture-audit/06.1-03-SUMMARY.md`
</output>
